{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agricultural Commodity Supply and Pricing Analysis in Kenya: Data Cleaning\n",
    "#### Author: Edward Njiru\n",
    "#### Date: September, 2024\n",
    "\n",
    "## Introduction\n",
    "This notebook focuses on cleaning and preparing a dataset that contains information on the supply and pricing of various agricultural commodities in Kenya. The dataset is a combination of seasonal crops, perennial crops, livestock, fresh and saltwater fish, and agricultural inputs.\n",
    "\n",
    "### Objectives\n",
    "- Handle missing values\n",
    "- Correct data types for price and date columns\n",
    "- Remove duplicates\n",
    "- Handle mixed data types\n",
    "- Prepare the dataset for exploratory data analysis (EDA) and future predictive modeling\n",
    "\n",
    "---\n",
    "\n",
    "### Data Inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>classification</th>\n",
       "      <th>grade</th>\n",
       "      <th>market</th>\n",
       "      <th>wholesale_price</th>\n",
       "      <th>retail_price</th>\n",
       "      <th>volume_supplied</th>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Dried</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>250.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>17/10/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>80.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>26/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>19/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>13/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>06/09/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                commodity classification grade              market  \\\n",
       "0  African butter catfish          Dried     -  Kipini Fish market   \n",
       "1  African butter catfish          Fresh     -  Kipini Fish market   \n",
       "2  African butter catfish          Fresh     -  Kipini Fish market   \n",
       "3  African butter catfish          Fresh     -  Kipini Fish market   \n",
       "4  African butter catfish          Fresh     -  Kipini Fish market   \n",
       "\n",
       "  wholesale_price retail_price volume_supplied      county        date  \n",
       "0           250.0        330.0            62.0  Tana-River  17/10/2023  \n",
       "1            80.0        150.0            17.0  Tana-River  26/09/2023  \n",
       "2           100.0        150.0            25.0  Tana-River  19/09/2023  \n",
       "3           100.0        160.0            28.0  Tana-River  13/09/2023  \n",
       "4           100.0        160.0            28.0  Tana-River  06/09/2023  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.DtypeWarning)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"H:\\Datasets\\Agriculture Kenya\\Food Prices\\KAMIS 2009-2024\\Combined dataset\\combined_datasets.csv\"\n",
    "combined_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "combined_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025569 entries, 0 to 1025568\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count    Dtype \n",
      "---  ------           --------------    ----- \n",
      " 0   commodity        1022563 non-null  object\n",
      " 1   classification   1019497 non-null  object\n",
      " 2   grade            1022563 non-null  object\n",
      " 3   market           1022563 non-null  object\n",
      " 4   wholesale_price  887397 non-null   object\n",
      " 5   retail_price     670271 non-null   object\n",
      " 6   volume_supplied  690755 non-null   object\n",
      " 7   county           1022563 non-null  object\n",
      " 8   date             1022563 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 70.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>classification</th>\n",
       "      <th>grade</th>\n",
       "      <th>market</th>\n",
       "      <th>wholesale_price</th>\n",
       "      <th>retail_price</th>\n",
       "      <th>volume_supplied</th>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1022563</td>\n",
       "      <td>1019497</td>\n",
       "      <td>1022563</td>\n",
       "      <td>1022563</td>\n",
       "      <td>887397.0</td>\n",
       "      <td>670271.0</td>\n",
       "      <td>690755.0</td>\n",
       "      <td>1022563</td>\n",
       "      <td>1022563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>176</td>\n",
       "      <td>149</td>\n",
       "      <td>16</td>\n",
       "      <td>301</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>8685.0</td>\n",
       "      <td>5049.0</td>\n",
       "      <td>49</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Cattle</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Nakuru Wakulima</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>24/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>39540</td>\n",
       "      <td>693406</td>\n",
       "      <td>916032</td>\n",
       "      <td>66486</td>\n",
       "      <td>44574.0</td>\n",
       "      <td>65104.0</td>\n",
       "      <td>23779.0</td>\n",
       "      <td>95561</td>\n",
       "      <td>70173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       commodity classification    grade           market  wholesale_price  \\\n",
       "count    1022563        1019497  1022563          1022563         887397.0   \n",
       "unique       176            149       16              301           9000.0   \n",
       "top       Cattle              -        -  Nakuru Wakulima             50.0   \n",
       "freq       39540         693406   916032            66486          44574.0   \n",
       "\n",
       "        retail_price  volume_supplied   county        date  \n",
       "count       670271.0         690755.0  1022563     1022563  \n",
       "unique        8685.0           5049.0       49        2078  \n",
       "top            100.0            200.0  Nairobi  24/05/2021  \n",
       "freq         65104.0          23779.0    95561       70173  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic dataset info and summary statistics\n",
    "combined_data.info()\n",
    "combined_data.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025569 entries, 0 to 1025568\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count    Dtype \n",
      "---  ------           --------------    ----- \n",
      " 0   commodity        1022563 non-null  object\n",
      " 1   classification   1019497 non-null  object\n",
      " 2   grade            1022563 non-null  object\n",
      " 3   market           1022563 non-null  object\n",
      " 4   wholesale_price  887397 non-null   object\n",
      " 5   retail_price     670271 non-null   object\n",
      " 6   volume_supplied  690755 non-null   object\n",
      " 7   county           1022563 non-null  object\n",
      " 8   date             1022563 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 70.4+ MB\n",
      "\n",
      "Missing Values per Column:\n",
      "commodity            3006\n",
      "classification       6072\n",
      "grade                3006\n",
      "market               3006\n",
      "wholesale_price    138172\n",
      "retail_price       355298\n",
      "volume_supplied    334814\n",
      "county               3006\n",
      "date                 3006\n",
      "dtype: int64\n",
      "\n",
      "Data Types for Each Column:\n",
      "commodity          object\n",
      "classification     object\n",
      "grade              object\n",
      "market             object\n",
      "wholesale_price    object\n",
      "retail_price       object\n",
      "volume_supplied    object\n",
      "county             object\n",
      "date               object\n",
      "dtype: object\n",
      "\n",
      "Number of Fully Blank Rows: 3006\n",
      "\n",
      "Preview of Fully Blank Rows:\n",
      "       commodity classification grade market wholesale_price retail_price  \\\n",
      "274517       NaN            NaN   NaN    NaN             NaN          NaN   \n",
      "274529       NaN            NaN   NaN    NaN             NaN          NaN   \n",
      "274540       NaN            NaN   NaN    NaN             NaN          NaN   \n",
      "274551       NaN            NaN   NaN    NaN             NaN          NaN   \n",
      "274563       NaN            NaN   NaN    NaN             NaN          NaN   \n",
      "\n",
      "       volume_supplied county date  \n",
      "274517             NaN    NaN  NaN  \n",
      "274529             NaN    NaN  NaN  \n",
      "274540             NaN    NaN  NaN  \n",
      "274551             NaN    NaN  NaN  \n",
      "274563             NaN    NaN  NaN  \n",
      "\n",
      "Number of Duplicate Rows: 42533\n",
      "\n",
      "Summary Statistics for Numerical Columns:\n",
      "       commodity classification    grade           market  wholesale_price  \\\n",
      "count    1022563        1019497  1022563          1022563         887397.0   \n",
      "unique       176            149       16              301           9000.0   \n",
      "top       Cattle              -        -  Nakuru Wakulima             50.0   \n",
      "freq       39540         693406   916032            66486          44574.0   \n",
      "\n",
      "        retail_price  volume_supplied   county        date  \n",
      "count       670271.0         690755.0  1022563     1022563  \n",
      "unique        8685.0           5049.0       49        2078  \n",
      "top            100.0            200.0  Nairobi  24/05/2021  \n",
      "freq         65104.0          23779.0    95561       70173  \n",
      "\n",
      "Unique Commodities: 177\n",
      "['African butter catfish' 'Alestes' 'Anchovies' 'Apples' 'Arrow Root'\n",
      " 'Avocado' 'Banana (Cooking)' 'Banana (Plantain)' 'Banana (Ripening)'\n",
      " 'Barbus' 'Barracuda(Kasumba)' 'Beans (Canadian wonder)'\n",
      " 'Beans (Mwezi Moja)' 'Black bass' 'Broccoli' 'Butternuts' 'Camel Hide'\n",
      " 'Camel meat' 'Camel milk(Processed)' 'Cassava Chips (dry)'\n",
      " 'Cassava Fresh' 'Cattle' 'Cattle Hide' 'Cauliflower' 'Chicken' 'Chillies'\n",
      " 'Coconut' 'Coconut Oil' 'Coffee' 'Common Carp' 'Coriander (Dhania)'\n",
      " 'Cotton' 'Cotton Seed' 'Courgette' 'Cowpeas' 'Cowpea leaves (Kunde)'\n",
      " 'Cow Milk(Processd)' 'Cuttlefish' 'Donkey' nan 'Dry Maize' 'commodity'\n",
      " 'Dry Onions' 'Dry Peas' 'Duck' 'Eggs' 'Egg plant (Brinjals)'\n",
      " 'Ethiopian Kales -Kanzira' 'Fertilizer' 'Fish Oil' 'Fish Scales'\n",
      " 'French beans' 'Fresh Peas' 'Fresh Water Shrimp' 'Garlic' 'Ginger' 'Goat'\n",
      " 'Goatfishes' 'Goat Milk (at collection point)' 'Goat milk (Processed)'\n",
      " 'Goat Skin' 'Golden (Deep-Sea) Crabs Kaa' 'Grapes' 'Green Grams'\n",
      " 'Green Maize' 'Ground Nuts' 'Groupers' 'Grunt(Taamamba/Kora)' 'Halfbeaks'\n",
      " 'Haplochromis' 'Honey' 'Indigenous Crotolaria (Mito/Miro)'\n",
      " 'Jacks/Trevallies(Kolekole)' 'Jobfish' 'Kingfish (Nguru)' 'Labeo'\n",
      " 'Lemons' 'Lentils' 'Lettuce' 'Limes' 'Lobster(Kamba Mawe)'\n",
      " 'Macademia Seed' 'Mackerel' 'Maize Bran' 'Maize Flour' 'Mangoes'\n",
      " 'Mangoes Local' 'Marlins' 'Meat Beef' 'Meat Broiler' 'Meat Chevon'\n",
      " 'Meat Indiginous Chicken' 'Meat Mutton' 'Mixed Beans' 'Mixed Demersal'\n",
      " 'Mixed Pelagics' 'Mormyrus' 'Mud Crabs' 'Mullets(Fumi)'\n",
      " 'Nderema- Vine Spinach' 'Needlefishes' 'Nile Perch Skins' 'Njugu Mawe'\n",
      " 'Octopus (Pweza)' \"Okra (Lady's fingers or Gumbo)\" 'Omena'\n",
      " 'Other Fresh Water' 'Oysters' 'Paddy' 'Parrotfishes(Pono)' 'Pasta'\n",
      " 'Pawpaw' 'Pigeon peas' 'Pigs' 'Pineapples' 'Pork' 'Prawns' 'Protopterus'\n",
      " 'Pumpkin' 'Pumpkin Leaves' 'Queenfish (Pandu)' 'Rabbit' 'Rabbit Meat '\n",
      " 'Rayfish' 'Red Sorghum' 'Fish Maws' 'Jute Plant (Murenda)'\n",
      " 'Passion Fruits' 'Beans Red Haricot (Wairimu)'\n",
      " 'Black nightshade (Managu/ Osuga)' 'Spider flower (Saga)' 'Oranges'\n",
      " 'Amaranthus (Terere)' 'Pepino melon' 'Tree tomato'\n",
      " 'Camel Milk(At collection point)' 'Yam' 'Cow Milk(At collection point)'\n",
      " 'Thorn melon' 'Kales/Sukuma Wiki' 'Cucumber' 'Nile Perch'\n",
      " 'Beans Rosecoco (Nyayo)' 'Spinach' 'Camel' 'Capsicums' 'Rice'\n",
      " 'Rockcode(Tewa)' 'Sailfishes' 'Sardines' 'Scavengers (Changu/Tangu)'\n",
      " 'Sharks' 'Sheep' 'Sheep Skin' 'Snappers(Tazanda)' 'Soybean oil'\n",
      " 'Spaghetti' 'Spring Onions' 'Squid(Ngisi)' 'Sunflower Cake'\n",
      " 'Sunflower Oil' 'Sunflower Seeds' 'Surgeonfishes' 'Swordfishes'\n",
      " 'Synodontis' 'Tangerine (Sandara)' 'Tea' 'Threadfin breams' 'Tilapia'\n",
      " 'Trout' 'Tuna' 'Water Melon' 'Wheat' 'Wheat Bran' 'Wheat Flour'\n",
      " 'White Irish Potatoes' 'Wolf Herrings']\n"
     ]
    }
   ],
   "source": [
    "# Check the data types and non-null counts of each column\n",
    "combined_data.info()\n",
    "\n",
    "# --- Check for Missing Values ---\n",
    "missing_values = combined_data.isnull().sum()\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# --- Check Data Types for Each Column ---\n",
    "data_types = combined_data.dtypes\n",
    "print(\"\\nData Types for Each Column:\")\n",
    "print(data_types)\n",
    "\n",
    "# --- Check for Fully Blank Rows ---\n",
    "fully_blank_rows = combined_data[combined_data.isnull().all(axis=1)]\n",
    "fully_blank_count = fully_blank_rows.shape[0]\n",
    "print(f\"\\nNumber of Fully Blank Rows: {fully_blank_count}\")\n",
    "\n",
    "# Display preview if any fully blank rows exist\n",
    "if fully_blank_count > 0:\n",
    "    print(f\"\\nPreview of Fully Blank Rows:\\n{fully_blank_rows.head()}\")\n",
    "\n",
    "# --- Check for Duplicate Rows ---\n",
    "duplicate_count = combined_data.duplicated().sum()\n",
    "print(f\"\\nNumber of Duplicate Rows: {duplicate_count}\")\n",
    "\n",
    "# --- View Summary Statistics of the Numerical Columns ---\n",
    "print(\"\\nSummary Statistics for Numerical Columns:\")\n",
    "print(combined_data.describe())\n",
    "\n",
    "# --- View Unique Values in 'commodity' Column to Understand Categories ---\n",
    "unique_commodities = combined_data['commodity'].unique()\n",
    "print(f\"\\nUnique Commodities: {len(unique_commodities)}\\n{unique_commodities}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Inspection Findings\n",
    "\n",
    "1. **Dataset Overview**:\n",
    "   - **Total Rows**: 1,025,569\n",
    "   - **Total Columns**: 9\n",
    "   - **Memory Usage**: 70.4 MB\n",
    "   - All columns are currently stored as `object` type, even those that should be numeric (prices and volume). The `date` column is stored as a string and needs to be converted to a proper `datetime` format.\n",
    "\n",
    "2. **Missing Values**:\n",
    "   - **commodity**: 3,006 missing values.\n",
    "   - **classification**: 6,072 missing values.\n",
    "   - **grade**: 3,006 missing values.\n",
    "   - **market**: 3,006 missing values.\n",
    "   - **wholesale_price**: 138,172 missing values.\n",
    "   - **retail_price**: 355,298 missing values.\n",
    "   - **volume_supplied**: 334,814 missing values.\n",
    "   - **county**: 3,006 missing values.\n",
    "   - **date**: 3,006 missing values.\n",
    "\n",
    "3. **Fully Blank Rows**:\n",
    "   - There are 3,006 fully blank rows (where all columns are NaN). These rows provide no valuable information and should be removed.\n",
    "\n",
    "4. **Duplicate Rows**:\n",
    "   - The dataset contains **42,533 duplicate rows**, which should be removed to prevent skewing analysis.\n",
    "\n",
    "5. **Summary Statistics**:\n",
    "   - **Commodity**: 176 unique values, with Cattle being the most frequent (39,540 occurrences).\n",
    "   - **Market**: 301 unique market locations.\n",
    "   - **Wholesale Price**: 9,000 unique values, most frequent being 50 KSH (44,574 occurrences).\n",
    "   - **Retail Price**: 8,685 unique values, most common being 100 KSH (65,104 occurrences).\n",
    "   - **Volume Supplied**: 5,049 unique values, with 200 kg as the most frequent volume supplied.\n",
    "   - **County**: 49 unique counties, with Nairobi being the most common.\n",
    "\n",
    "6. **Commodities**:\n",
    "   - There are 177 unique commodity entries, ranging from crops to livestock, fish, and other goods. Some entries contain NaN values that should be addressed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "In this section, I will clean the dataset by:\n",
    "1. Removing fully blank rows and duplicates.\n",
    "2. Renaming columns for clarity.\n",
    "3. Handling missing values (imputation and filling).\n",
    "4. Converting data types.\n",
    "5. Calculating resell profit.\n",
    "6. Rearranging columns for better organization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing fully blank and duplicate rows: 983035\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Delete Fully Blank Rows\n",
    "# Remove rows where all column values are NaN, as these rows do not provide any valuable information.\n",
    "combined_data.dropna(how='all', inplace=True)\n",
    "\n",
    "# Step 2: Remove Duplicate Rows\n",
    "# Drop any duplicate rows in the dataset to ensure data integrity.\n",
    "combined_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check the result after handling blank and duplicate rows\n",
    "print(\"Number of rows after removing fully blank and duplicate rows:\", combined_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>classification</th>\n",
       "      <th>grade</th>\n",
       "      <th>market</th>\n",
       "      <th>wholesale_price_ksh</th>\n",
       "      <th>retail_price_ksh</th>\n",
       "      <th>volume_supplied_kg</th>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Dried</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>250.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>17/10/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>80.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>26/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>19/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>13/09/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>-</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>06/09/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                commodity classification grade              market  \\\n",
       "0  African butter catfish          Dried     -  Kipini Fish market   \n",
       "1  African butter catfish          Fresh     -  Kipini Fish market   \n",
       "2  African butter catfish          Fresh     -  Kipini Fish market   \n",
       "3  African butter catfish          Fresh     -  Kipini Fish market   \n",
       "4  African butter catfish          Fresh     -  Kipini Fish market   \n",
       "\n",
       "  wholesale_price_ksh retail_price_ksh volume_supplied_kg      county  \\\n",
       "0               250.0            330.0               62.0  Tana-River   \n",
       "1                80.0            150.0               17.0  Tana-River   \n",
       "2               100.0            150.0               25.0  Tana-River   \n",
       "3               100.0            160.0               28.0  Tana-River   \n",
       "4               100.0            160.0               28.0  Tana-River   \n",
       "\n",
       "         date  \n",
       "0  17/10/2023  \n",
       "1  26/09/2023  \n",
       "2  19/09/2023  \n",
       "3  13/09/2023  \n",
       "4  06/09/2023  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Rename Columns\n",
    "# Rename columns for consistency and better understanding. This makes the column names more readable.\n",
    "combined_data.rename(columns={\n",
    "    'wholesale_price': 'wholesale_price_ksh',\n",
    "    'retail_price': 'retail_price_ksh',\n",
    "    'volume_supplied': 'volume_supplied_kg'\n",
    "}, inplace=True)\n",
    "\n",
    "# Display the first few rows to verify changes\n",
    "combined_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining Missing Values per Column:\n",
      "commodity              0\n",
      "classification         0\n",
      "grade                  0\n",
      "market                 0\n",
      "wholesale_price_ksh    0\n",
      "retail_price_ksh       0\n",
      "volume_supplied_kg     0\n",
      "county                 0\n",
      "date                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Handle Missing Price, Volume, and Categorical Values\n",
    "# Convert columns to numeric first, impute missing values using the mean between the previous and next valid values,\n",
    "# then apply forward fill to fill any remaining gaps, and finally handle categorical missing values.\n",
    "\n",
    "# Convert price and volume columns to numeric (coerce any invalid values to NaN)\n",
    "combined_data['wholesale_price_ksh'] = pd.to_numeric(combined_data['wholesale_price_ksh'], errors='coerce')\n",
    "combined_data['retail_price_ksh'] = pd.to_numeric(combined_data['retail_price_ksh'], errors='coerce')\n",
    "combined_data['volume_supplied_kg'] = pd.to_numeric(combined_data['volume_supplied_kg'], errors='coerce')\n",
    "\n",
    "# Function to impute missing values by calculating the mean between the previous and next valid values\n",
    "def impute_mean_between(data_series):\n",
    "    nan_indices = data_series[data_series.isna()].index\n",
    "    for i in nan_indices:\n",
    "        prev_value = data_series[:i].last_valid_index()\n",
    "        next_value = data_series[i:].first_valid_index()\n",
    "        if prev_value is not None and next_value is not None:\n",
    "            mean_value = (data_series[prev_value] + data_series[next_value]) / 2\n",
    "            data_series.at[i] = mean_value\n",
    "    return data_series\n",
    "\n",
    "# Apply the imputation function to wholesale_price_ksh, retail_price_ksh, and volume_supplied_kg\n",
    "combined_data['wholesale_price_ksh'] = impute_mean_between(combined_data['wholesale_price_ksh'])\n",
    "combined_data['retail_price_ksh'] = impute_mean_between(combined_data['retail_price_ksh'])\n",
    "combined_data['volume_supplied_kg'] = impute_mean_between(combined_data['volume_supplied_kg'])\n",
    "\n",
    "# Apply forward fill for any remaining missing values\n",
    "combined_data['wholesale_price_ksh'] = combined_data['wholesale_price_ksh'].ffill()\n",
    "combined_data['retail_price_ksh'] = combined_data['retail_price_ksh'].ffill()\n",
    "combined_data['volume_supplied_kg'] = combined_data['volume_supplied_kg'].ffill()\n",
    "\n",
    "# Handle missing values in 'classification' column by filling with 'Regular'\n",
    "combined_data['classification'].fillna('Regular', inplace=True)\n",
    "\n",
    "# Display the first few rows after handling missing values\n",
    "combined_data.head()\n",
    "\n",
    "# Check remaining missing values to ensure everything is filled correctly\n",
    "print(\"\\nRemaining Missing Values per Column:\")\n",
    "print(combined_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unnecessary Columns\n",
    "\n",
    "In this step, we will remove rows where the `market` column has missing values, as `market` is an essential feature for our analysis. Having missing data in this column could hinder accurate market-level insights.\n",
    "\n",
    "Additionally, we will drop the `grade` column because it contains many insignificant values and overlaps with the `classification` column. The `classification` column already provides sufficient differentiation for our analysis, making `grade` redundant.\n",
    "\n",
    "This will streamline the dataset and remove unnecessary complexity, allowing for a more focused analysis moving forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining Missing Values per Column After Dropping 'market' and 'grade':\n",
      "commodity              0\n",
      "classification         0\n",
      "market                 0\n",
      "wholesale_price_ksh    0\n",
      "retail_price_ksh       0\n",
      "volume_supplied_kg     0\n",
      "county                 0\n",
      "date                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Drop rows where 'market' column has missing values\n",
    "combined_data.dropna(subset=['market'], inplace=True)\n",
    "\n",
    "# Drop the 'grade' column as it overlaps with 'classification' and contains many insignificant values\n",
    "combined_data.drop(columns=['grade'], inplace=True)\n",
    "\n",
    "# Display the first few rows to confirm the changes\n",
    "combined_data.head()\n",
    "\n",
    "# Check if there are any remaining missing values after dropping the 'market' column\n",
    "print(\"\\nRemaining Missing Values per Column After Dropping 'market' and 'grade':\")\n",
    "print(combined_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Date Column as Index and Rearranging Columns\n",
    "\n",
    "In this step, I will set the `date` column as the index of the dataset to enable time-series operations. Time is a crucial factor for analysis in this project, especially when analyzing trends in commodity pricing and supply over time.\n",
    "\n",
    "Additionally, I will rearrange the remaining columns in a logical order, with `commodity`, `classification`, and `county` appearing first, followed by the price and volume columns.\n",
    "\n",
    "This rearrangement will streamline the dataset, making it easier to work with and analyze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavilion\\AppData\\Local\\Temp\\ipykernel_9884\\885785799.py:2: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  combined_data['date'] = pd.to_datetime(combined_data['date'], errors='coerce')  # Ensure 'date' is in datetime format\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index Type and Sample Data:\n",
      "DatetimeIndex(['2023-10-17', '2023-09-26', '2023-09-19', '2023-09-13',\n",
      "               '2023-09-06', '2023-09-05', '2023-09-04', '2023-08-15',\n",
      "               '2023-08-14', '2023-08-07',\n",
      "               ...\n",
      "               '2022-10-24', '2022-09-08', '2021-11-04', '2021-10-13',\n",
      "               '2021-05-24', '2021-05-24', '2021-05-24', '2021-05-24',\n",
      "               '2021-05-24', '2021-05-24'],\n",
      "              dtype='datetime64[ns]', name='date', length=983035, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Set the 'date' column as the index for time-series analysis\n",
    "combined_data['date'] = pd.to_datetime(combined_data['date'], errors='coerce')  # Ensure 'date' is in datetime format\n",
    "combined_data.set_index('date', inplace=True)\n",
    "\n",
    "# Rearrange the columns in a logical order\n",
    "columns_order = ['commodity', 'classification', 'county', 'market', \n",
    "                 'volume_supplied_kg', 'wholesale_price_ksh', 'retail_price_ksh']\n",
    "\n",
    "# Apply the new column order\n",
    "combined_data = combined_data[columns_order]\n",
    "\n",
    "# Display the updated dataframe to confirm changes\n",
    "combined_data.head()\n",
    "\n",
    "# Check the index to ensure 'date' is correctly set\n",
    "print(\"\\nIndex Type and Sample Data:\")\n",
    "print(combined_data.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Volume to Tonnes\n",
    "\n",
    "In this step, I will convert the `volume_supplied_kg` column to tonnes, as 1 tonne equals 1,000 kg. I will then rename the column to `volume_supplied_tonnes` for clarity and drop the original `volume_supplied_kg` column, which is no longer needed.\n",
    "\n",
    "This conversion allows for easier interpretation and comparison of commodity volumes, especially when dealing with larger quantities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>classification</th>\n",
       "      <th>county</th>\n",
       "      <th>market</th>\n",
       "      <th>wholesale_price_ksh</th>\n",
       "      <th>retail_price_ksh</th>\n",
       "      <th>volume_supplied_tonnes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-17</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Dried</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>250.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-26</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>80.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-13</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-06</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         commodity classification      county  \\\n",
       "date                                                            \n",
       "2023-10-17  African butter catfish          Dried  Tana-River   \n",
       "2023-09-26  African butter catfish          Fresh  Tana-River   \n",
       "2023-09-19  African butter catfish          Fresh  Tana-River   \n",
       "2023-09-13  African butter catfish          Fresh  Tana-River   \n",
       "2023-09-06  African butter catfish          Fresh  Tana-River   \n",
       "\n",
       "                        market  wholesale_price_ksh  retail_price_ksh  \\\n",
       "date                                                                    \n",
       "2023-10-17  Kipini Fish market                250.0             330.0   \n",
       "2023-09-26  Kipini Fish market                 80.0             150.0   \n",
       "2023-09-19  Kipini Fish market                100.0             150.0   \n",
       "2023-09-13  Kipini Fish market                100.0             160.0   \n",
       "2023-09-06  Kipini Fish market                100.0             160.0   \n",
       "\n",
       "            volume_supplied_tonnes  \n",
       "date                                \n",
       "2023-10-17                   0.062  \n",
       "2023-09-26                   0.017  \n",
       "2023-09-19                   0.025  \n",
       "2023-09-13                   0.028  \n",
       "2023-09-06                   0.028  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Convert 'volume_supplied_kg' to 'volume_supplied_tonnes'\n",
    "combined_data['volume_supplied_tonnes'] = combined_data['volume_supplied_kg'] / 1000\n",
    "\n",
    "# Drop the original 'volume_supplied_kg' column if it's no longer needed\n",
    "combined_data.drop(columns=['volume_supplied_kg'], inplace=True)\n",
    "\n",
    "# Display the first few rows to confirm the changes\n",
    "combined_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>classification</th>\n",
       "      <th>county</th>\n",
       "      <th>market</th>\n",
       "      <th>volume_supplied_tonnes</th>\n",
       "      <th>wholesale_price_ksh</th>\n",
       "      <th>retail_price_ksh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-17</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Dried</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>0.062</td>\n",
       "      <td>250.0</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-26</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>0.017</td>\n",
       "      <td>80.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>0.025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-13</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>0.028</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-06</th>\n",
       "      <td>African butter catfish</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Tana-River</td>\n",
       "      <td>Kipini Fish market</td>\n",
       "      <td>0.028</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         commodity classification      county  \\\n",
       "date                                                            \n",
       "2023-10-17  African butter catfish          Dried  Tana-River   \n",
       "2023-09-26  African butter catfish          Fresh  Tana-River   \n",
       "2023-09-19  African butter catfish          Fresh  Tana-River   \n",
       "2023-09-13  African butter catfish          Fresh  Tana-River   \n",
       "2023-09-06  African butter catfish          Fresh  Tana-River   \n",
       "\n",
       "                        market  volume_supplied_tonnes  wholesale_price_ksh  \\\n",
       "date                                                                          \n",
       "2023-10-17  Kipini Fish market                   0.062                250.0   \n",
       "2023-09-26  Kipini Fish market                   0.017                 80.0   \n",
       "2023-09-19  Kipini Fish market                   0.025                100.0   \n",
       "2023-09-13  Kipini Fish market                   0.028                100.0   \n",
       "2023-09-06  Kipini Fish market                   0.028                100.0   \n",
       "\n",
       "            retail_price_ksh  \n",
       "date                          \n",
       "2023-10-17             330.0  \n",
       "2023-09-26             150.0  \n",
       "2023-09-19             150.0  \n",
       "2023-09-13             160.0  \n",
       "2023-09-06             160.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearrange the columns to place 'volume_supplied_tonnes' after 'market'\n",
    "columns_order = ['commodity', 'classification', 'county', 'market', \n",
    "                 'volume_supplied_tonnes', 'wholesale_price_ksh', 'retail_price_ksh']\n",
    "\n",
    "# Apply the new column order\n",
    "combined_data = combined_data[columns_order]\n",
    "\n",
    "# Display the updated dataframe to confirm the changes\n",
    "combined_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-inspecting the DataFrame\n",
    "\n",
    "Now that the volume has been converted, I will re-inspect the dataset to ensure everything looks correct. This includes checking the basic structure of the DataFrame, such as data types, missing values, and summary statistics for numerical columns like prices and volume.\n",
    "\n",
    "These checks will give me a preliminary understanding of the data distributions before proceeding with visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 983035 entries, 2023-10-17 to 2021-05-24\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   commodity               983035 non-null  object \n",
      " 1   classification          983035 non-null  object \n",
      " 2   county                  983035 non-null  object \n",
      " 3   market                  983035 non-null  object \n",
      " 4   volume_supplied_tonnes  983035 non-null  float64\n",
      " 5   wholesale_price_ksh     983035 non-null  float64\n",
      " 6   retail_price_ksh        983035 non-null  float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 60.0+ MB\n",
      "\n",
      "Summary Statistics for Numerical Columns:\n",
      "       volume_supplied_tonnes  wholesale_price_ksh  retail_price_ksh\n",
      "count           983035.000000         9.830350e+05      9.830350e+05\n",
      "mean                 5.329091         2.544467e+03      2.898955e+03\n",
      "std                359.856038         4.920758e+04      1.519309e+04\n",
      "min                  0.000000         0.000000e+00      0.000000e+00\n",
      "25%                  0.140000         3.714000e+01      7.000000e+01\n",
      "50%                  0.560000         7.000000e+01      1.075000e+02\n",
      "75%                  2.000000         1.500000e+02      2.000000e+02\n",
      "max              99999.999990         1.575000e+07      4.000000e+06\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Re-inspect the data and check basic statistics\n",
    "print(\"\\nData Summary:\")\n",
    "combined_data.info()\n",
    "\n",
    "print(\"\\nSummary Statistics for Numerical Columns:\")\n",
    "print(combined_data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Issues in the Summary Statistics\n",
    "\n",
    "Upon inspecting the summary statistics for the numerical columns (`volume_supplied_tonnes`, `wholesale_price_ksh`, and `retail_price_ksh`), a few inconsistencies stand out that require further investigation:\n",
    "\n",
    "1. **Minimum Values of 0**: \n",
    "   - The `volume_supplied_tonnes`, `wholesale_price_ksh`, and `retail_price_ksh` columns all have minimum values of 0. This is problematic because:\n",
    "     - For **volume**: A value of 0 suggests that no commodity was supplied to the market, which contradicts the expectation that the data records only active sales and market supplies.\n",
    "     - For **prices**: A value of 0 for both wholesale and retail prices is illogical, as it implies that commodities were traded for free, which is highly unlikely in a market setting.\n",
    "   \n",
    "   These entries need to be investigated further to determine whether they are errors, missing data that were improperly handled, or actual records with special meanings.\n",
    "\n",
    "2. **Extreme Maximum Values**: \n",
    "   - The maximum value for **wholesale price** is over 15 million KSH, and for **retail price**, it is 4 million KSH. These values are extremely high and may represent data entry errors or outliers.\n",
    "   \n",
    "   I will investigate these extreme values and decide on the appropriate treatment, such as capping or removing them if they are deemed outliers.\n",
    "\n",
    "3. **Distribution of Data**: \n",
    "   - After addressing the zero values and extreme outliers, I will inspect the distribution of these columns to ensure the data is reasonable for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with zero volume: 8020\n",
      "Rows with zero wholesale price: 57\n",
      "Rows with zero retail price: 3\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of zero values in volume, wholesale price, and retail price\n",
    "zero_volume_count = combined_data[combined_data['volume_supplied_tonnes'] == 0].shape[0]\n",
    "zero_wholesale_count = combined_data[combined_data['wholesale_price_ksh'] == 0].shape[0]\n",
    "zero_retail_count = combined_data[combined_data['retail_price_ksh'] == 0].shape[0]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Rows with zero volume: {zero_volume_count}\")\n",
    "print(f\"Rows with zero wholesale price: {zero_wholesale_count}\")\n",
    "print(f\"Rows with zero retail price: {zero_retail_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Summary After Dropping Zero Values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 975006 entries, 2023-10-17 to 2021-05-24\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   commodity               975006 non-null  object \n",
      " 1   classification          975006 non-null  object \n",
      " 2   county                  975006 non-null  object \n",
      " 3   market                  975006 non-null  object \n",
      " 4   volume_supplied_tonnes  975006 non-null  float64\n",
      " 5   wholesale_price_ksh     975006 non-null  float64\n",
      " 6   retail_price_ksh        975006 non-null  float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 59.5+ MB\n",
      "\n",
      "Summary Statistics After Dropping Zero Values:\n",
      "       volume_supplied_tonnes  wholesale_price_ksh  retail_price_ksh\n",
      "count           975006.000000         9.750060e+05      9.750060e+05\n",
      "mean                 5.372975         2.564285e+03      2.919383e+03\n",
      "std                361.334350         4.940918e+04      1.524976e+04\n",
      "min                  0.000050         1.000000e-02      1.000000e-02\n",
      "25%                  0.150000         3.684500e+01      7.000000e+01\n",
      "50%                  0.581000         7.000000e+01      1.080000e+02\n",
      "75%                  2.000000         1.500000e+02      2.000000e+02\n",
      "max              99999.999990         1.575000e+07      4.000000e+06\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Drop rows where volume, wholesale price, or retail price is zero\n",
    "\n",
    "# Drop rows where volume_supplied_tonnes is 0\n",
    "combined_data = combined_data[combined_data['volume_supplied_tonnes'] != 0]\n",
    "\n",
    "# Drop rows where wholesale_price_ksh is 0\n",
    "combined_data = combined_data[combined_data['wholesale_price_ksh'] != 0]\n",
    "\n",
    "# Drop rows where retail_price_ksh is 0\n",
    "combined_data = combined_data[combined_data['retail_price_ksh'] != 0]\n",
    "\n",
    "# Re-inspect the dataset to confirm changes\n",
    "print(\"\\nData Summary After Dropping Zero Values:\")\n",
    "combined_data.info()\n",
    "\n",
    "print(\"\\nSummary Statistics After Dropping Zero Values:\")\n",
    "print(combined_data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Outliers Using the IQR Method\n",
    "\n",
    "In this step, I will calculate outliers for each commodity using the **Interquartile Range (IQR)** method. This approach is better suited for handling the variety of commodities in the dataset, as it accounts for differences in the price and volume distributions.\n",
    "\n",
    "The IQR method defines outliers as values that fall below the lower bound or above the upper bound:\n",
    "- Lower bound: Q1 - 1.5 * IQR\n",
    "- Upper bound: Q3 + 1.5 * IQR\n",
    "\n",
    "I will calculate the number of outliers in each of the following columns:\n",
    "- `volume_supplied_tonnes`\n",
    "- `wholesale_price_ksh`\n",
    "- `retail_price_ksh`\n",
    "\n",
    "This will be done on a **commodity-specific basis** to ensure that each commoditys characteristics are considered when identifying outliers. I will summarize the results in a table to count the number of outliers for each commodity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>volume_outliers</th>\n",
       "      <th>wholesale_price_outliers</th>\n",
       "      <th>retail_price_outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cattle</td>\n",
       "      <td>4875</td>\n",
       "      <td>542</td>\n",
       "      <td>9320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Goat</td>\n",
       "      <td>4515</td>\n",
       "      <td>1104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Sheep</td>\n",
       "      <td>3805</td>\n",
       "      <td>832</td>\n",
       "      <td>5598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>2838</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Dry Onions</td>\n",
       "      <td>2802</td>\n",
       "      <td>2543</td>\n",
       "      <td>4792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Rabbit Meat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Barbus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cotton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>commodity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Threadfin breams</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            commodity  volume_outliers  wholesale_price_outliers  \\\n",
       "21             Cattle             4875                       542   \n",
       "55               Goat             4515                      1104   \n",
       "151             Sheep             3805                       832   \n",
       "44               Eggs             2838                        95   \n",
       "41         Dry Onions             2802                      2543   \n",
       "..                ...              ...                       ...   \n",
       "121      Rabbit Meat                 0                         0   \n",
       "9              Barbus                0                         0   \n",
       "31             Cotton                0                         0   \n",
       "40          commodity                0                         0   \n",
       "166  Threadfin breams                0                         0   \n",
       "\n",
       "     retail_price_outliers  \n",
       "21                    9320  \n",
       "55                       1  \n",
       "151                   5598  \n",
       "44                      70  \n",
       "41                    4792  \n",
       "..                     ...  \n",
       "121                      1  \n",
       "9                        0  \n",
       "31                       0  \n",
       "40                       0  \n",
       "166                      0  \n",
       "\n",
       "[176 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate IQR and count outliers for each commodity\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "\n",
    "# Create a list to store the outlier summary data\n",
    "outlier_summary_list = []\n",
    "\n",
    "# Loop through each commodity and count the outliers\n",
    "for commodity in combined_data['commodity'].unique():\n",
    "    # Filter by commodity\n",
    "    commodity_data = combined_data[combined_data['commodity'] == commodity]\n",
    "    \n",
    "    # Count outliers in volume, wholesale price, and retail price\n",
    "    volume_outliers = detect_outliers_iqr(commodity_data, 'volume_supplied_tonnes').sum()\n",
    "    wholesale_outliers = detect_outliers_iqr(commodity_data, 'wholesale_price_ksh').sum()\n",
    "    retail_outliers = detect_outliers_iqr(commodity_data, 'retail_price_ksh').sum()\n",
    "    \n",
    "    # Append to the list\n",
    "    outlier_summary_list.append({\n",
    "        'commodity': commodity,\n",
    "        'volume_outliers': volume_outliers,\n",
    "        'wholesale_price_outliers': wholesale_outliers,\n",
    "        'retail_price_outliers': retail_outliers\n",
    "    })\n",
    "\n",
    "# Convert the list into a DataFrame\n",
    "outlier_summary = pd.DataFrame(outlier_summary_list)\n",
    "\n",
    "# Display the summary of outliers\n",
    "outlier_summary.sort_values(by=['volume_outliers', 'wholesale_price_outliers', 'retail_price_outliers'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping All Outliers Using the IQR Method\n",
    "\n",
    "In this step, I will drop all outliers identified using the **Interquartile Range (IQR)** method. This is done on a commodity-specific basis, where outliers in the `volume_supplied_tonnes`, `wholesale_price_ksh`, and `retail_price_ksh` columns are removed. \n",
    "\n",
    "Since they are less than 0.02% of the dataset, the noise will skew the visual analysis and Machine Learning Model.\n",
    "\n",
    "After dropping the outliers, I will re-inspect the dataset to confirm that it is clean and ready for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated dataset info after dropping all outliers:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 783418 entries, 2023-09-26 to 2021-05-24\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   commodity               783418 non-null  object \n",
      " 1   classification          783418 non-null  object \n",
      " 2   county                  783418 non-null  object \n",
      " 3   market                  783418 non-null  object \n",
      " 4   volume_supplied_tonnes  783418 non-null  float64\n",
      " 5   wholesale_price_ksh     783418 non-null  float64\n",
      " 6   retail_price_ksh        783418 non-null  float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 47.8+ MB\n",
      "\n",
      "Summary Statistics After Dropping All Outliers:\n",
      "       volume_supplied_tonnes  wholesale_price_ksh  retail_price_ksh\n",
      "count           783418.000000        783418.000000     783418.000000\n",
      "mean                 1.452679          1642.937342       2906.764626\n",
      "std                  2.964624          7276.211424      13909.523931\n",
      "min                  0.000050             0.010000          0.010000\n",
      "25%                  0.132500            35.560000         65.000000\n",
      "50%                  0.500000            65.000000        100.000000\n",
      "75%                  1.500000           130.000000        175.000000\n",
      "max                 80.000000        125000.000000     200000.000000\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store cleaned data for each commodity\n",
    "cleaned_data_chunks = []\n",
    "\n",
    "# Loop through each commodity and drop the outliers identified using the IQR method\n",
    "for commodity in combined_data['commodity'].unique():\n",
    "    # Filter the data for each commodity\n",
    "    commodity_data = combined_data[combined_data['commodity'] == commodity].copy()\n",
    "    \n",
    "    # Identify outliers in volume, wholesale price, and retail price\n",
    "    volume_outliers = detect_outliers_iqr(commodity_data, 'volume_supplied_tonnes')\n",
    "    wholesale_outliers = detect_outliers_iqr(commodity_data, 'wholesale_price_ksh')\n",
    "    retail_outliers = detect_outliers_iqr(commodity_data, 'retail_price_ksh')\n",
    "    \n",
    "    # Drop outliers\n",
    "    commodity_cleaned_data = commodity_data[~(volume_outliers | wholesale_outliers | retail_outliers)]\n",
    "    \n",
    "    # Append cleaned commodity data to the list\n",
    "    cleaned_data_chunks.append(commodity_cleaned_data)\n",
    "\n",
    "# Concatenate the list of cleaned data back into a single DataFrame\n",
    "combined_data_cleaned = pd.concat(cleaned_data_chunks)\n",
    "\n",
    "# Re-inspect the dataset to confirm changes after dropping all outliers\n",
    "print(\"\\nUpdated dataset info after dropping all outliers:\")\n",
    "combined_data_cleaned.info()\n",
    "\n",
    "# Recheck summary statistics after handling outliers\n",
    "print(\"\\nSummary Statistics After Dropping All Outliers:\")\n",
    "print(combined_data_cleaned.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Rows Where Retail Prices are Lower than Wholesale Prices\n",
    "\n",
    "In this step, I will identify and drop rows where the `retail_price_ksh` is lower than the `wholesale_price_ksh`. This is a clear data entry error since retail prices should logically be higher than wholesale prices. These erroneous rows will be removed to ensure the integrity of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample rows where retail price is lower than wholesale price:\n",
      "            commodity classification        county                    market  \\\n",
      "date                                                                           \n",
      "2021-07-07    Alestes          Dried         Nandi  Chepterit Market - Nandi   \n",
      "2021-05-24  Anchovies              -         Kwale                  Mwangulu   \n",
      "2024-09-15     Apples              -        Kisumu                    Kibuye   \n",
      "2024-09-14     Apples              -       Nairobi          Nairobi Wakulima   \n",
      "2024-09-06     Apples              -  Taita-Taveta                Voi Retail   \n",
      "\n",
      "            volume_supplied_tonnes  wholesale_price_ksh  retail_price_ksh  \n",
      "date                                                                       \n",
      "2021-07-07                  0.1000              125.000             100.0  \n",
      "2021-05-24                  0.2000              214.290             200.0  \n",
      "2024-09-15                  0.1225              223.235             200.0  \n",
      "2024-09-14                  0.0750              360.000             250.0  \n",
      "2024-09-06                  0.0200              188.335              40.0  \n",
      "\n",
      "Updated dataset info after dropping invalid retail prices:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 674730 entries, 2023-09-26 to 2021-05-24\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   commodity               674730 non-null  object \n",
      " 1   classification          674730 non-null  object \n",
      " 2   county                  674730 non-null  object \n",
      " 3   market                  674730 non-null  object \n",
      " 4   volume_supplied_tonnes  674730 non-null  float64\n",
      " 5   wholesale_price_ksh     674730 non-null  float64\n",
      " 6   retail_price_ksh        674730 non-null  float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 41.2+ MB\n",
      "\n",
      "Summary Statistics After Dropping Invalid Prices:\n",
      "       volume_supplied_tonnes  wholesale_price_ksh  retail_price_ksh\n",
      "count           674730.000000        674730.000000     674730.000000\n",
      "mean                 1.567298          1287.219874       3279.208967\n",
      "std                  3.081440          6816.233621      14864.238845\n",
      "min                  0.000050             0.010000          0.010000\n",
      "25%                  0.200000            31.580000         70.000000\n",
      "50%                  0.600000            58.890000        100.000000\n",
      "75%                  1.710000           100.000000        180.000000\n",
      "max                 80.000000        125000.000000     200000.000000\n"
     ]
    }
   ],
   "source": [
    "# Step: Drop rows where retail price is lower than wholesale price\n",
    "invalid_price_rows = combined_data_cleaned[combined_data_cleaned['retail_price_ksh'] < combined_data_cleaned['wholesale_price_ksh']]\n",
    "\n",
    "# Display a sample of these rows for review\n",
    "print(\"\\nSample rows where retail price is lower than wholesale price:\")\n",
    "print(invalid_price_rows.head())\n",
    "\n",
    "# Drop the invalid rows\n",
    "combined_data_cleaned = combined_data_cleaned[combined_data_cleaned['retail_price_ksh'] >= combined_data_cleaned['wholesale_price_ksh']]\n",
    "\n",
    "# Confirm that the rows have been dropped\n",
    "print(\"\\nUpdated dataset info after dropping invalid retail prices:\")\n",
    "combined_data_cleaned.info()\n",
    "\n",
    "# Recheck summary statistics to ensure the dataset is still clean\n",
    "print(\"\\nSummary Statistics After Dropping Invalid Prices:\")\n",
    "print(combined_data_cleaned.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Final Inspection of the Cleaned Dataset\n",
    "\n",
    "After completing the cleaning process by handling outliers and removing invalid rows where retail prices were lower than wholesale prices, I will now perform a final inspection of the dataset to ensure it is fully clean and ready for analysis.\n",
    "\n",
    "The final checks will include checking for missing values: Ensuring no missing values remain in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values After Cleaning:\n",
      "commodity                 0\n",
      "classification            0\n",
      "county                    0\n",
      "market                    0\n",
      "volume_supplied_tonnes    0\n",
      "wholesale_price_ksh       0\n",
      "retail_price_ksh          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining missing values in the dataset\n",
    "missing_values = combined_data_cleaned.isnull().sum()\n",
    "print(\"\\nMissing Values After Cleaning:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Final Step: Splitting the Dataset into Categorical Datasets\n",
    "\n",
    "In this step, I will split the combined dataset into separate datasets based on the predefined categories: **Seasonal Crops**, **Perennial Crops**, **Livestock**, **Meat**, **Animal Products**, **Animal By-products**, **Salt Water Fish**, **Fresh Water Fish**, and **Agricultural Inputs**. Any commodities that do not fit into these categories will be grouped into an \"Other\" category.\n",
    "\n",
    "After splitting, I will inspect the first few rows of each categorical dataset to ensure they are correctly assigned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique commodities in Seasonal Crops Data:\n",
      "['Arrow Root' 'Beans (Canadian wonder)' 'Beans (Mwezi Moja)' 'Broccoli'\n",
      " 'Butternuts' 'Cassava Chips (dry)' 'Cassava Fresh' 'Cauliflower'\n",
      " 'Chillies' 'Coriander (Dhania)' 'Courgette' 'Cowpeas'\n",
      " 'Cowpea leaves (Kunde)' 'Dry Maize' 'Dry Onions' 'Dry Peas'\n",
      " 'Egg plant (Brinjals)' 'French beans' 'Fresh Peas' 'Garlic' 'Ginger'\n",
      " 'Green Grams' 'Green Maize' 'Ground Nuts'\n",
      " 'Indigenous Crotolaria (Mito/Miro)' 'Lentils' 'Lettuce' 'Maize Bran'\n",
      " 'Maize Flour' 'Mixed Beans' 'Nderema- Vine Spinach' 'Njugu Mawe'\n",
      " \"Okra (Lady's fingers or Gumbo)\" 'Pawpaw' 'Pigeon peas' 'Pumpkin'\n",
      " 'Pumpkin Leaves' 'Red Sorghum' 'Jute Plant (Murenda)'\n",
      " 'Beans Red Haricot (Wairimu)' 'Black nightshade (Managu/ Osuga)'\n",
      " 'Spider flower (Saga)' 'Amaranthus (Terere)' 'Yam' 'Thorn melon'\n",
      " 'Kales/Sukuma Wiki' 'Cucumber' 'Beans Rosecoco (Nyayo)' 'Spinach'\n",
      " 'Capsicums' 'Rice' 'Soybean oil' 'Spring Onions' 'Sunflower Cake'\n",
      " 'Sunflower Oil' 'Sunflower Seeds' 'Tangerine (Sandara)' 'Water Melon'\n",
      " 'Wheat' 'Wheat Bran' 'Wheat Flour' 'White Irish Potatoes'] \n",
      "\n",
      "Unique commodities in Perennial Crops Data:\n",
      "['Apples' 'Avocado' 'Banana (Cooking)' 'Banana (Plantain)'\n",
      " 'Banana (Ripening)' 'Coffee' 'Cotton' 'Cotton Seed' 'Grapes' 'Lemons'\n",
      " 'Limes' 'Macademia Seed' 'Mangoes Local' 'Pineapples' 'Passion Fruits'\n",
      " 'Oranges' 'Pepino melon' 'Tree tomato' 'Tea'] \n",
      "\n",
      "Unique commodities in Livestock Data:\n",
      "['Cattle' 'Chicken' 'Donkey' 'Duck' 'Goat' 'Camel' 'Sheep'] \n",
      "\n",
      "Unique commodities in Meat Data:\n",
      "['Camel meat' 'Meat Beef' 'Meat Broiler' 'Meat Chevon' 'Meat Mutton'\n",
      " 'Pork' 'Rabbit Meat'] \n",
      "\n",
      "Unique commodities in Animal Products Data:\n",
      "['Camel milk(Processed)' 'Eggs' 'Fish Oil' 'Honey'] \n",
      "\n",
      "Unique commodities in Animal By-products Data:\n",
      "['Camel Hide' 'Cattle Hide' 'Fish Scales' 'Goat Skin' 'Nile Perch Skins'\n",
      " 'Sheep Skin'] \n",
      "\n",
      "Unique commodities in Salt Water Fish Data:\n",
      "['Anchovies' 'Barracuda(Kasumba)' 'Cuttlefish' 'Goatfishes'\n",
      " 'Golden (Deep-Sea) Crabs Kaa' 'Groupers' 'Grunt(Taamamba/Kora)'\n",
      " 'Halfbeaks' 'Jacks/Trevallies(Kolekole)' 'Jobfish' 'Kingfish (Nguru)'\n",
      " 'Lobster(Kamba Mawe)' 'Mackerel' 'Marlins' 'Mud Crabs' 'Mullets(Fumi)'\n",
      " 'Octopus (Pweza)' 'Oysters' 'Parrotfishes(Pono)' 'Prawns'\n",
      " 'Queenfish (Pandu)' 'Rayfish' 'Rockcode(Tewa)' 'Sailfishes' 'Sardines'\n",
      " 'Scavengers (Changu/Tangu)' 'Sharks' 'Snappers(Tazanda)' 'Squid(Ngisi)'\n",
      " 'Surgeonfishes' 'Swordfishes' 'Threadfin breams' 'Tuna' 'Wolf Herrings'] \n",
      "\n",
      "Unique commodities in Fresh Water Fish Data:\n",
      "['African butter catfish' 'Alestes' 'Barbus' 'Black bass' 'Common Carp'\n",
      " 'Fresh Water Shrimp' 'Haplochromis' 'Labeo' 'Mixed Demersal'\n",
      " 'Mixed Pelagics' 'Mormyrus' 'Omena' 'Protopterus' 'Nile Perch'\n",
      " 'Synodontis' 'Tilapia' 'Trout'] \n",
      "\n",
      "Unique commodities in Agricultural Inputs Data:\n",
      "['Fertilizer'] \n",
      "\n",
      "Unique commodities in Other Data (if any):\n",
      "['Coconut' 'Coconut Oil' 'Cow Milk(Processd)' 'Ethiopian Kales -Kanzira'\n",
      " 'Goat Milk (at collection point)' 'Goat milk (Processed)' 'Mangoes'\n",
      " 'Meat Indiginous Chicken' 'Needlefishes' 'Other Fresh Water' 'Paddy'\n",
      " 'Fish Maws' 'Camel Milk(At collection point)'\n",
      " 'Cow Milk(At collection point)'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, drop 'Pasta', 'Spaghetti', and any 'commodity' placeholders from the dataset\n",
    "combined_data_cleaned = combined_data_cleaned[~combined_data_cleaned['commodity'].isin(['Pasta', 'Spaghetti', 'commodity'])]\n",
    "\n",
    "# Strip leading and trailing spaces in the 'commodity' column\n",
    "combined_data_cleaned['commodity'] = combined_data_cleaned['commodity'].str.strip()\n",
    "\n",
    "# Define commodity categories as lists\n",
    "seasonal_crops = ['Arrow Root', 'Beans (Canadian wonder)', 'Beans (Mwezi Moja)', 'Beans Rosecoco (Nyayo)', \n",
    "                  'Beans Red Haricot (Wairimu)', 'Black nightshade (Managu/ Osuga)', 'Broccoli', 'Butternuts',\n",
    "                  'Cassava Chips (dry)', 'Cassava Fresh', 'Cauliflower', 'Chillies', 'Coriander (Dhania)', \n",
    "                  'Cowpeas', 'Cowpea leaves (Kunde)', 'Courgette', 'Dry Maize', 'Dry Onions', 'Dry Peas', \n",
    "                  'Egg plant (Brinjals)', 'Ethiopian Kales - Kanzira', 'French beans', 'Fresh Peas', 'Garlic', \n",
    "                  'Ginger', 'Green Grams', 'Green Maize', 'Ground Nuts', 'Indigenous Crotolaria (Mito/Miro)', \n",
    "                  'Jute Plant (Murenda)', 'Lentils', 'Lettuce', 'Maize Bran', 'Maize Flour', 'Mixed Beans', \n",
    "                  'Nderema- Vine Spinach', 'Okra (Lady\\'s fingers or Gumbo)', 'Pawpaw', 'Pigeon peas', 'Pumpkin', \n",
    "                  'Pumpkin Leaves', 'Red Sorghum', 'Spinach', 'Spider flower (Saga)', 'Sunflower Cake', 'Sunflower Oil', \n",
    "                  'Sunflower Seeds', 'Sweet Potatoes', 'Thorn melon', 'Water Melon', 'Wheat', 'Wheat Bran', \n",
    "                  'Wheat Flour', 'White Irish Potatoes', 'Yam', 'Kales/Sukuma Wiki', 'Cucumber', 'Capsicums', \n",
    "                  'Amaranthus (Terere)', 'Spring Onions', 'Tangerine (Sandara)', 'Rice', 'Njugu Mawe', 'Soybean oil']\n",
    "\n",
    "perennial_crops = ['Apples', 'Avocado', 'Banana (Cooking)', 'Banana (Plantain)', 'Banana (Ripening)', 'Grapes', \n",
    "                   'Lemons', 'Limes', 'Mangoes Exotic', 'Mangoes Local', 'Oranges', 'Passion Fruits', 'Pineapples', \n",
    "                   'Coffee', 'Cotton', 'Cotton Seed', 'Macademia Seed', 'Pepino melon', 'Tea', 'Tree tomato']\n",
    "\n",
    "livestock = ['Camel', 'Cattle', 'Chicken', 'Donkey', 'Duck', 'Goat', 'Sheep']\n",
    "\n",
    "meat = ['Camel meat', 'Meat Beef', 'Meat Broiler', 'Meat Chevon', 'Meat Indigenous Chicken', 'Meat Mutton', \n",
    "        'Pork', 'Rabbit Meat']\n",
    "\n",
    "animal_products = ['Cow Milk (At collection point)', 'Cow Milk (Processed)', 'Goat Milk (At collection point)', \n",
    "                   'Goat Milk (Processed)', 'Camel Milk (At collection point)', 'Camel milk(Processed)', 'Eggs', \n",
    "                   'Honey', 'Fish Oil']\n",
    "\n",
    "animal_byproducts = ['Camel Hide', 'Cattle Hide', 'Goat Skin', 'Sheep Skin', 'Fish Scales', 'Nile Perch Skins']\n",
    "\n",
    "salt_water_fish = ['Anchovies', 'Barracuda(Kasumba)', 'Cuttlefish', 'Golden (Deep-Sea) Crabs Kaa', 'Goatfishes', \n",
    "                   'Groupers', 'Grunt(Taamamba/Kora)', 'Halfbeaks', 'Jobfish', 'Kingfish (Nguru)', 'Lobster(Kamba Mawe)', \n",
    "                   'Mackerel', 'Mud Crabs', 'Mullets(Fumi)', 'Octopus (Pweza)', 'Oysters', 'Parrotfishes(Pono)', \n",
    "                   'Queenfish (Pandu)', 'Rayfish', 'Rockcode(Tewa)', 'Sailfishes', 'Sardines', 'Scavengers (Changu/Tangu)', \n",
    "                   'Sharks', 'Snappers(Tazanda)', 'Surgeonfishes', 'Swordfishes', 'Threadfin breams', 'Tuna', 'Wolf Herrings', \n",
    "                   'Jacks/Trevallies(Kolekole)', 'Marlins', 'Prawns', 'Squid(Ngisi)']\n",
    "\n",
    "fresh_water_fish = ['African butter catfish', 'Alestes', 'Barbus', 'Black bass', 'Common Carp', 'Fresh Water Shrimp', \n",
    "                    'Haplochromis', 'Mixed Demersal', 'Mixed Pelagics', 'Nile Perch', 'Protopterus', 'Synodontis', \n",
    "                    'Tilapia', 'Trout', 'Omena', 'Labeo', 'Mormyrus']\n",
    "\n",
    "agricultural_inputs = ['Fertilizer']\n",
    "\n",
    "# Create separate datasets\n",
    "seasonal_crops_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(seasonal_crops)]\n",
    "perennial_crops_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(perennial_crops)]\n",
    "livestock_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(livestock)]\n",
    "meat_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(meat)]\n",
    "animal_products_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(animal_products)]\n",
    "animal_byproducts_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(animal_byproducts)]\n",
    "salt_water_fish_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(salt_water_fish)]\n",
    "fresh_water_fish_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(fresh_water_fish)]\n",
    "agricultural_inputs_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(agricultural_inputs)]\n",
    "\n",
    "# Check for any commodities that don't fit into any category (Other category)\n",
    "all_categorized_commodities = (seasonal_crops + perennial_crops + livestock + meat + animal_products + \n",
    "                               animal_byproducts + salt_water_fish + fresh_water_fish + agricultural_inputs)\n",
    "\n",
    "other_data = combined_data_cleaned[~combined_data_cleaned['commodity'].isin(all_categorized_commodities)]\n",
    "\n",
    "# Return unique commodities in each dataset\n",
    "print(\"Unique commodities in Seasonal Crops Data:\")\n",
    "print(seasonal_crops_data['commodity'].unique(), \"\\n\")\n",
    "\n",
    "print(\"Unique commodities in Perennial Crops Data:\")\n",
    "print(perennial_crops_data['commodity'].unique(), \"\\n\")\n",
    "\n",
    "print(\"Unique commodities in Livestock Data:\")\n",
    "print(livestock_data['commodity'].unique(), \"\\n\")\n",
    "\n",
    "print(\"Unique commodities in Meat Data:\")\n",
    "print(meat_data['commodity'].unique(), \"\\n\")\n",
    "\n",
    "print(\"Unique commodities in Animal Products Data:\")\n",
    "print(animal_products_data['commodity'].unique(), \"\\n\")\n",
    "\n",
    "print(\"Unique commodities in Animal By-products Data:\")\n",
    "print(animal_byproducts_data['commodity'].unique(), \"\\n\")\n",
    "\n",
    "print(\"Unique commodities in Salt Water Fish Data:\")\n",
    "print(salt_water_fish_data['commodity'].unique(), \"\\n\")\n",
    "\n",
    "print(\"Unique commodities in Fresh Water Fish Data:\")\n",
    "print(fresh_water_fish_data['commodity'].unique(), \"\\n\")\n",
    "\n",
    "print(\"Unique commodities in Agricultural Inputs Data:\")\n",
    "print(agricultural_inputs_data['commodity'].unique(), \"\\n\")\n",
    "\n",
    "print(\"Unique commodities in Other Data (if any):\")\n",
    "print(other_data['commodity'].unique(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identified Data Entry Issues and the Way Forward\n",
    "\n",
    "After inspecting the unique commodities in the \"Other Data\" category, it is clear that several commodities are incorrectly classified due to minor typing inconsistencies or formatting issues. For example, items like `'Cow Milk(Processd)'` and `'Goat milk (Processed)'` have inconsistent spacing, capitalization, or punctuation.\n",
    "\n",
    "**Way Forward**:\n",
    "1. **Fix Typing Issues**: I will normalize these commodity names by correcting the inconsistent names using replacements.\n",
    "2. **Reassign Commodities**: After correcting the typing errors, I will reassign these commodities to their appropriate categories.\n",
    "3. **Update Categories**: Once the commodities are correctly assigned, they will be appended to their respective categorical datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique commodities in Other Data (if any):\n",
      "['Coconut' 'Coconut Oil' 'Needlefishes' 'Other Fresh Water' 'Paddy'\n",
      " 'Fish Maws'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fix Typing Issues in the 'commodity' Column\n",
    "corrections = {\n",
    "    'Cow Milk(Processd)': 'Cow Milk (Processed)',\n",
    "    'Goat milk (Processed)': 'Goat Milk (Processed)',\n",
    "    'Goat Milk (at collection point)': 'Goat Milk (At collection point)',\n",
    "    'Mangoes': 'Mangoes Exotic',  # Assuming this refers to exotic mangoes\n",
    "    'Meat Indiginous Chicken': 'Meat Indigenous Chicken',  # Correct the spelling\n",
    "    'Camel Milk(At collection point)': 'Camel Milk (At collection point)',\n",
    "    'Cow Milk(At collection point)': 'Cow Milk (At collection point)',\n",
    "    'Ethiopian Kales -Kanzira': 'Ethiopian Kales - Kanzira',\n",
    "    'Needlefishes': 'Needlefishes',  # Assuming this is correct\n",
    "    'Soybean oil': 'Soybean oil'  # Move this to Seasonal Crops as requested\n",
    "}\n",
    "\n",
    "# Apply corrections to the 'commodity' column\n",
    "combined_data_cleaned['commodity'] = combined_data_cleaned['commodity'].replace(corrections)\n",
    "\n",
    "# Step 2: Reassign corrected commodities to their respective categories\n",
    "# Reassign these commodities after correcting typing issues\n",
    "\n",
    "# Update the seasonal crops category to include 'Soybean oil'\n",
    "seasonal_crops.append('Soybean oil')\n",
    "\n",
    "# Recreate the datasets after fixing the typing issues\n",
    "seasonal_crops_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(seasonal_crops)]\n",
    "perennial_crops_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(perennial_crops)]\n",
    "livestock_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(livestock)]\n",
    "meat_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(meat)]\n",
    "animal_products_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(animal_products)]\n",
    "animal_byproducts_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(animal_byproducts)]\n",
    "salt_water_fish_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(salt_water_fish)]\n",
    "fresh_water_fish_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(fresh_water_fish)]\n",
    "agricultural_inputs_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(agricultural_inputs)]\n",
    "\n",
    "# Step 3: Check for any remaining commodities that don't fit into any category (Other category)\n",
    "all_categorized_commodities = (seasonal_crops + perennial_crops + livestock + meat + animal_products + \n",
    "                               animal_byproducts + salt_water_fish + fresh_water_fish + agricultural_inputs)\n",
    "\n",
    "other_data = combined_data_cleaned[~combined_data_cleaned['commodity'].isin(all_categorized_commodities)]\n",
    "\n",
    "# Return unique commodities in Other Data again to check if everything has been properly categorized\n",
    "print(\"Unique commodities in Other Data (if any):\")\n",
    "print(other_data['commodity'].unique(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique commodities in Other Data (if any):\n",
      "[] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Correctly assign the remaining commodities to their respective categories\n",
    "# Add 'Coconut' and 'Coconut Oil' to Perennial Crops\n",
    "perennial_crops += ['Coconut', 'Coconut Oil']\n",
    "\n",
    "# Add 'Other Fresh Water' and 'Fish Maws' to Fresh Water Fish\n",
    "fresh_water_fish += ['Other Fresh Water', 'Fish Maws']\n",
    "\n",
    "# Add 'Paddy' to Seasonal Crops (since it's similar to rice)\n",
    "seasonal_crops.append('Paddy')\n",
    "\n",
    "# Add 'Needlefishes' to Salt Water Fish\n",
    "salt_water_fish.append('Needlefishes')\n",
    "\n",
    "# Step 2: Recreate the datasets with the updated category lists\n",
    "seasonal_crops_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(seasonal_crops)]\n",
    "perennial_crops_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(perennial_crops)]\n",
    "livestock_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(livestock)]\n",
    "meat_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(meat)]\n",
    "animal_products_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(animal_products)]\n",
    "animal_byproducts_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(animal_byproducts)]\n",
    "salt_water_fish_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(salt_water_fish)]\n",
    "fresh_water_fish_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(fresh_water_fish)]\n",
    "agricultural_inputs_data = combined_data_cleaned[combined_data_cleaned['commodity'].isin(agricultural_inputs)]\n",
    "\n",
    "# Step 3: Check if there are any remaining commodities in the \"Other\" category\n",
    "all_categorized_commodities = (seasonal_crops + perennial_crops + livestock + meat + animal_products + \n",
    "                               animal_byproducts + salt_water_fish + fresh_water_fish + agricultural_inputs)\n",
    "\n",
    "other_data = combined_data_cleaned[~combined_data_cleaned['commodity'].isin(all_categorized_commodities)]\n",
    "\n",
    "# Step 4: Inspect the \"Other Data\" to ensure all commodities are correctly assigned\n",
    "print(\"Unique commodities in Other Data (if any):\")\n",
    "print(other_data['commodity'].unique(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exporting the Combined Dataset and Categorical Datasets into CSV Files\n",
    "\n",
    "In this step, I will export the combined dataset and all individual category datasets into CSV files. These CSV files will be used for further analysis in separate notebooks, where exploratory data analysis (EDA) and preprocessing will be conducted for each category before moving toward predictive model building for supply volumes and market prices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the combined dataset to CSV\n",
    "combined_data_cleaned.to_csv('combined_dataset_cleaned.csv', index=True)\n",
    "\n",
    "# Export the individual categorical datasets to CSV\n",
    "seasonal_crops_data.to_csv('seasonal_crops_data.csv', index=True)\n",
    "perennial_crops_data.to_csv('perennial_crops_data.csv', index=True)\n",
    "livestock_data.to_csv('livestock_data.csv', index=True)\n",
    "meat_data.to_csv('meat_data.csv', index=True)\n",
    "animal_products_data.to_csv('animal_products_data.csv', index=True)\n",
    "animal_byproducts_data.to_csv('animal_byproducts_data.csv', index=True)\n",
    "salt_water_fish_data.to_csv('salt_water_fish_data.csv', index=True)\n",
    "fresh_water_fish_data.to_csv('fresh_water_fish_data.csv', index=True)\n",
    "agricultural_inputs_data.to_csv('agricultural_inputs_data.csv', index=True)\n",
    "\n",
    "# Check if any commodities were not categorized (Other category)\n",
    "if not other_data.empty:\n",
    "    other_data.to_csv('other_data.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conclusion and Areas of Further Analysis\n",
    "\n",
    "This project has successfully cleaned, processed, and categorized the agricultural dataset into meaningful groups, allowing for better analysis and insight extraction. The data has been categorized into **Seasonal Crops**, **Perennial Crops**, **Livestock**, **Meat**, **Animal Products**, **Animal By-products**, **Salt Water Fish**, **Fresh Water Fish**, and **Agricultural Inputs**. \n",
    "\n",
    "The next steps will involve conducting **Exploratory Data Analysis (EDA)** for each category in separate notebooks to further investigate trends in pricing and supply volumes. The aim will be to identify patterns in the data, including **seasonal trends**, **geographical supply trends**, and **price fluctuations** across different commodities and markets.\n",
    "\n",
    "Following EDA, the focus will be on **building predictive models** to forecast:\n",
    "1. **Supply Volumes**: Using time series and regression analysis to predict how supply volumes vary over time and across regions.\n",
    "2. **Market Prices**: Developing predictive models to forecast wholesale and retail prices, enabling stakeholders to make data-driven decisions.\n",
    "\n",
    "Key areas of exploration include:\n",
    "- **Seasonality and Cyclical Patterns**: Identifying seasonal patterns in supply volumes and pricing for different commodities.\n",
    "- **Geographical Analysis**: Investigating how supply and demand trends differ across regions and markets.\n",
    "- **Market Linkage and Optimization**: Exploring how market players can better align their supply chains to maximize profitability and efficiency.\n",
    "\n",
    "With this data, we can aim to build robust models that provide actionable insights for farmers, market players, and other stakeholders involved in the agricultural value chain.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    " 2024 All rights reserved. \n",
    "\n",
    "Prepared by: Edward Njiru  \n",
    "Project: Agricultural Commodity Supply and Pricing Analysis  \n",
    "Date: September 2024  \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
